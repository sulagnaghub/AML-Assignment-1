{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wwb4TEKoUDcZ",
        "outputId": "bf798aca-bbbf-4069-833a-e8700c1fa8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/emailspam_splits.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POkH_a12UZcM",
        "outputId": "353b0dc9-26aa-4852-be49-ac2c4471b0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/emailspam_splits.zip\n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "YeUXb5LY3Ezq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfeJ7Fxr7SvQ"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('/content/train.csv')\n",
        "train_labels = pd.read_csv('/content/train_labels.csv')\n",
        "\n",
        "test_data = pd.read_csv('/content/test.csv')\n",
        "test_labels = pd.read_csv('/content/test_labels.csv')\n",
        "\n",
        "validation_data = pd.read_csv('/content/validation.csv')\n",
        "validation_labels = pd.read_csv('/content/validation_labels.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting a model on train data"
      ],
      "metadata": {
        "id": "S4vczLcM7uFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the models\n",
        "models = {\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'SVM': SVC(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "# Initialize TF-IDF\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "# Transform the datasets\n",
        "X_train = tfidf.fit_transform(train_data['preprocessed_text'])\n",
        "X_test = tfidf.transform(test_data['preprocessed_text'])\n",
        "y_train = train_labels['spam']\n",
        "y_test = test_labels['spam']\n",
        "\n",
        "# Fit the models and evaluate\n",
        "model_metrics = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Fit model\n",
        "    model.fit(X_train, y_train)\n",
        "    # Predict on test data\n",
        "    y_pred = model.predict(X_test)\n",
        "    # Extract metrics\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    model_metrics[name] = {\n",
        "        'precision': report['weighted avg']['precision'],\n",
        "        'recall': report['weighted avg']['recall'],\n",
        "        'f1-score': report['weighted avg']['f1-score'],\n",
        "        'accuracy': accuracy\n",
        "    }"
      ],
      "metadata": {
        "id": "s7VRRsrC3mWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scoring models on given data\n"
      ],
      "metadata": {
        "id": "aVsmm-TJ78-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtWKTdMR78VN",
        "outputId": "176525b1-5099-4a21-8ca3-93c2ec43e456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Naive Bayes': {'precision': 0.8943115183246072,\n",
              "  'recall': 0.8769633507853403,\n",
              "  'f1-score': 0.8615968192553174,\n",
              "  'accuracy': 0.8769633507853403},\n",
              " 'SVM': {'precision': 0.986984867077805,\n",
              "  'recall': 0.9869109947643979,\n",
              "  'f1-score': 0.9868247635518099,\n",
              "  'accuracy': 0.9869109947643979},\n",
              " 'Logistic Regression': {'precision': 0.980453554312941,\n",
              "  'recall': 0.9799301919720768,\n",
              "  'f1-score': 0.9796438812250124,\n",
              "  'accuracy': 0.9799301919720768},\n",
              " 'Random Forest': {'precision': 0.9690470347170281,\n",
              "  'recall': 0.9677137870855148,\n",
              "  'f1-score': 0.9669418450039897,\n",
              "  'accuracy': 0.9677137870855148},\n",
              " 'Gradient Boosting': {'precision': 0.9739014846252999,\n",
              "  'recall': 0.9738219895287958,\n",
              "  'f1-score': 0.9735339602470555,\n",
              "  'accuracy': 0.9738219895287958}}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the model predictions"
      ],
      "metadata": {
        "id": "RI0JQxzV8ECb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation in the Context of Non-Spam Classification:\n",
        "--------------------------------------------------------\n",
        "\n",
        "In the context of non-spam email classification of a skewed dataset, where the primary concern is to avoid misclassifying legitimate emails as spam, certain key metrics come into focus:\n",
        "\n",
        "1. Precision for the Spam Class:\n",
        "   - SVM (Support Vector Machine) demonstrates the highest precision, at approximately 98.70%.\n",
        "   - Logistic Regression closely follows with a precision of around 98.05%.\n",
        "   - These models excel in ensuring that when they predict an email as spam, it is indeed very likely to be spam. This is crucial for preventing false alarms and preserving the integrity of non-spam emails.\n",
        "\n",
        "2. Recall for the Spam Class:\n",
        "   - Capturing actual spam is important to maintain the effectiveness of the spam filter.\n",
        "   - SVM and Logistic Regression perform well in this aspect, with recall rates of approximately 98.69% and 97.99%, respectively.\n",
        "   - These models are adept at correctly identifying a high percentage of actual spam emails.\n",
        "\n",
        "Overall, SVM emerges as an excellent choice for spam classification in this scenario:\n",
        "- It exhibits both high precision and recall for the spam class, balancing the need to avoid misclassifying non-spam while effectively capturing spam.\n",
        "- SVM also maintains a high overall accuracy rate, demonstrating its robustness in classifying all emails accurately.\n",
        "\n",
        "Other two potential candidates are Logistic Regression and Gradient Boosting\n"
      ],
      "metadata": {
        "id": "0hHEpjrTcbHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validating the model"
      ],
      "metadata": {
        "id": "uzbVSW758I0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define hyperparameter grids for each model\n",
        "hyperparameter_grids = {\n",
        "    'Naive Bayes': {'alpha': [0.1, 0.5, 1.0, 1.5]},\n",
        "    'SVM': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly']},\n",
        "    'Logistic Regression': {'C': [0.1, 1, 10]},\n",
        "    'Random Forest': {'n_estimators': [50, 100, 200]},\n",
        "    'Gradient Boosting': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}\n",
        "}\n",
        "\n",
        "# Initialize an empty dictionary to store the best precision scores for each model\n",
        "best_precision_scores_with_validation = {}\n",
        "best_models_with_validation = {}\n",
        "best_hyperparameters_with_validation = {}\n",
        "\n",
        "# Loop through each model and perform grid search with validation set\n",
        "for model_name, model in models.items():\n",
        "    # Create a grid search for the current model\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=hyperparameter_grids[model_name],\n",
        "                               scoring='precision_weighted', cv=None, n_jobs=-1)\n",
        "\n",
        "    # Initialize TF-IDF vectorizer\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "    # Transform the training and validation data using TF-IDF\n",
        "    X_train_tfidf = tfidf_vectorizer.fit_transform(train_data['preprocessed_text'])\n",
        "    X_validation_tfidf = tfidf_vectorizer.transform(validation_data['preprocessed_text'])\n",
        "\n",
        "    # Train the grid search on the TF-IDF transformed training data\n",
        "    grid_search.fit(X_train_tfidf, train_labels['spam'])\n",
        "\n",
        "    # Store the best model and its hyperparameters\n",
        "    best_models_with_validation[model_name] = grid_search.best_estimator_\n",
        "    best_hyperparameters_with_validation[model_name] = grid_search.best_params_\n",
        "\n",
        "    # Evaluate the best model on the TF-IDF transformed validation data and store the precision score\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_validation_tfidf)\n",
        "    precision = precision_score(validation_labels['spam'], y_pred, average='weighted')\n",
        "    best_precision_scores_with_validation[model_name] = precision\n",
        "\n",
        "best_precision_scores_with_validation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2P9WvQH8MiG",
        "outputId": "a530ae18-7a92-467d-a57b-d69e5b829c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Naive Bayes': 0.9869701797900545,\n",
              " 'SVM': 0.9939025473570182,\n",
              " 'Logistic Regression': 0.9921376865859194,\n",
              " 'Random Forest': 0.9766855497564325,\n",
              " 'Gradient Boosting': 0.9711114372532532}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hyperparameters_with_validation"
      ],
      "metadata": {
        "id": "jltPgX-hmK2-",
        "outputId": "fe3c8fd9-e20f-421d-e57c-fe162a83bdb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Naive Bayes': {'alpha': 0.1},\n",
              " 'SVM': {'C': 1, 'kernel': 'linear'},\n",
              " 'Logistic Regression': {'C': 10},\n",
              " 'Random Forest': {'n_estimators': 200},\n",
              " 'Gradient Boosting': {'learning_rate': 0.1, 'n_estimators': 200}}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scoring 3 benchmark models on test data and selecting the best one"
      ],
      "metadata": {
        "id": "wQyYo8898R1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Rank 1: SVM\n",
        "- Rank 2: Logistic Regression\n",
        "- Rank 3: Naive Bayes"
      ],
      "metadata": {
        "id": "xcanTnzPj48z"
      }
    }
  ]
}